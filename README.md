# ğŸ›ï¸ Voice Shopping Assistant

An AIâ€‘powered, voiceâ€‘enabled shopping assistant tailored for kids and parents. Users can ask natural language queriesâ€”typed or spokenâ€”and receive personalized product recommendations (with images, descriptions, prices, and saveâ€‘forâ€‘later functionality) powered by a local LLaMAâ€‘2 (13B) model via Ollama, FastAPI backend, and Streamlit frontend.  


## ğŸ” Problem  
Parents and children often struggle to find ageâ€‘appropriate, educational or fun products online. Traditional search boxes require precise keywords and overwhelm users with thousands of results. Our solution enables handsâ€‘free, conversational shopping with AIâ€‘driven recommendations.

---

## ğŸ’¡ Solution  
- **Voice & Text Input:** Speak or type queries like â€œSuggest something spaceâ€‘themed for a 10â€‘yearâ€‘old.â€  
- **Personalized Sidebar:** Capture user name, age, and interests.  
- **LLM Recommendations:** Local LLaMAâ€‘2 (13B) model via Ollama generates concise product suggestions.  
- **Product Cards:** Display image, description, tags, and price.  
- **Save for Later:** Users can bookmark favorites, reviewed in a â€œâ¤ï¸ Your Saved Itemsâ€ section.  

---

## ğŸ› ï¸ Tech Stack  
| Layer                    | Technology                                    |
|--------------------------|-----------------------------------------------|
| **Frontend/UI**          | [Streamlit](https://streamlit.io)             |
| **Voice I/O**            | `speech_recognition` + Google Web Speech API (input), `gTTS` (output) |
| **Backend**              | [FastAPI](https://fastapi.tiangolo.com)       |
| **LLM Engine**           | [Ollama](https://ollama.ai) + LLaMAâ€‘2 (13B)    |
| **Data Storage**         | Static JSON product catalog                   |
| **Deployment (Demo)**    | Localhost (Streamlit + Uvicorn)               |

---

## ğŸ“¥ Installation

1. **Clone the repo**  

   * git clone https://github.com/YOUR_USERNAME/voice-shopping-assistant.git
   * cd voice-shopping-assistant


2. **Backend Setup**

  
   * cd server
   * python3 -m venv venv
   * source venv/bin/activate            # Windows: venv\Scripts\activate
   * pip install -r requirements.txt


3. **Frontend Setup (Streamlit)**

   * cd ../client2
   * python3 -m venv venv
   * source venv/bin/activate
   * pip install -r requirements.txt


4. **Ollama & LLaMAâ€‘2**

   * Install Ollama: `brew install ollama` (macOS) or follow [docs](https://ollama.ai).
   * Download LLaMAâ€‘2 13B: `ollama pull llama2`
   * Start local server:

   
     ollama run llama2
 

---

## â–¶ï¸ Running Locally

1. **Start Backend**

   cd server
   uvicorn app.main:app --reload


2. **Start Frontend**


   cd client2
   streamlit run app.py
  

3. **Open Browser**
   Visit `http://localhost:8501` to interact with your Voice Shopping Assistant.

---

## ğŸ§‘â€ğŸ’» Usage

* **Set Preferences:** Use the sidebar to enter name, age, and interests.
* **Type or Speak:** Click ğŸ™ï¸ or type a query in the text box.
* **Get Recommendations:** View AIâ€™s response, product card, and price.
* **Save Items:** Click ğŸ’¾ to bookmark products in â€œâ¤ï¸ Your Saved Items.â€

---

## ğŸ¤ Contributing

Contributions, ideas, and pull requests are welcome! Please open an issue or submit a PR.

---

## ğŸ“„ License

This project is released under the MIT License. See [LICENSE](LICENSE) for details.

---

```
```
